{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97920676",
   "metadata": {},
   "source": [
    "# RAG with Gemini + Pinecone + LangChain (Python)\n",
    "\n",
    "> A tiny, beginner‑friendly notebook to learn Retrieval‑Augmented Generation (RAG) step by step — with very little code.\n",
    "\n",
    "**What you’ll learn**  \n",
    "1. What RAG is and why it’s useful  \n",
    "2. How to index your docs in Pinecone using Gemini embeddings  \n",
    "3. How to retrieve the most relevant chunks for a user’s question  \n",
    "4. How to let Gemini read those chunks and answer — with sources\n",
    "\n",
    "**Stack**  \n",
    "- **LLM:** Google Gemini \n",
    "- **Vector DB:** Pinecone  \n",
    "- **Framework:** LangChain  \n",
    "- **Language:** Python\n",
    "\n",
    "> You’ll only need two API keys: **Google Generative AI** and **Pinecone**.\n",
    "\n",
    "```text\n",
    "                ┌────────────────────┐\n",
    "                │      Client        │\n",
    "                │ (User Question)    │\n",
    "                └────────┬───────────┘\n",
    "                         │\n",
    "                         ▼\n",
    "                ┌──────────────────────┐\n",
    "                │    Framework         │\n",
    "                │ (Python + LangChain) │\n",
    "                └────────┬─────────────┘\n",
    "                         │\n",
    "          (1) Semantic Search from Question Embedding\n",
    "                         │\n",
    "                         ▼\n",
    "                ┌────────────────────┐\n",
    "                │   Vector DB        │\n",
    "                │   (Pinecone)       │\n",
    "                │ Stores document    │\n",
    "                │ embeddings         │\n",
    "                └────────┬───────────┘\n",
    "                         │\n",
    "          (2) Retrieve Top Relevant Chunks\n",
    "                         │\n",
    "                         ▼\n",
    "                ┌────────────────────┐\n",
    "                │  Gemini (LLM)      │\n",
    "                │  Reads context +   │\n",
    "                │  question → Answer │\n",
    "                └────────┬───────────┘\n",
    "                         │\n",
    "          (3) Return Final Response\n",
    "                         │\n",
    "                         ▼\n",
    "                ┌────────────────────┐\n",
    "                │     Client         │\n",
    "                │ (Answer Displayed) │\n",
    "                └────────────────────┘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b01b08",
   "metadata": {},
   "source": [
    "## 0) Prerequisites\n",
    "\n",
    "- Create accounts and get API keys:\n",
    "  - **Google Generative AI**: https://ai.google.dev/\n",
    "  - **Pinecone**: https://www.pinecone.io/\n",
    "- Save keys in `.env` file. \n",
    "- Your `.env` file should have `GOOGLE_API_KEY` & `PINECONE_API_KEY`\n",
    "- Make sure you’re on Python 3.10+.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc1699",
   "metadata": {},
   "source": [
    "## 1) Install libraries \n",
    "\n",
    "Run this once per environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661b613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If you're in Colab, uncomment the next line:\n",
    "!pip -q install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f0827",
   "metadata": {},
   "source": [
    "## 2) Extract your API keys from `.env` file\n",
    "\n",
    "- We’ll read keys from environment variables to keep them out of source control.\n",
    "- If you prefer, just paste directly when prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd749a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys set in this session. ✅\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY') or getpass.getpass('Enter GOOGLE_API_KEY: ')\n",
    "os.environ['PINECONE_API_KEY'] = os.getenv('PINECONE_API_KEY') or getpass.getpass('Enter PINECONE_API_KEY: ')\n",
    "\n",
    "print('Keys set in this session. ✅')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab006ea",
   "metadata": {},
   "source": [
    "## 3) What is RAG? (plain English)\n",
    "\n",
    "**Problem:** LLMs don’t know your private data and can hallucinate.  \n",
    "**RAG idea:** 1) **Retrieve** the best passages from your knowledge base, then 2) **Generate** an answer that **cites** those passages.  \n",
    "This keeps answers grounded in your data, is cheaper than fine‑tuning, and updates instantly when you add new docs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acec53",
   "metadata": {},
   "source": [
    "## 4) Tiny pdf to play with \n",
    "\n",
    "To keep it simple, we'll use a sample pdf which can be used as context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce18cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 327 0 (offset 0)\n",
      "Ignoring wrong pointing object 329 0 (offset 0)\n",
      "Ignoring wrong pointing object 331 0 (offset 0)\n",
      "Ignoring wrong pointing object 333 0 (offset 0)\n",
      "Ignoring wrong pointing object 335 0 (offset 0)\n",
      "Ignoring wrong pointing object 337 0 (offset 0)\n",
      "Ignoring wrong pointing object 339 0 (offset 0)\n",
      "Ignoring wrong pointing object 341 0 (offset 0)\n",
      "Ignoring wrong pointing object 343 0 (offset 0)\n",
      "Ignoring wrong pointing object 345 0 (offset 0)\n",
      "Ignoring wrong pointing object 347 0 (offset 0)\n",
      "Ignoring wrong pointing object 355 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 44389 characters from PDF\n",
      "Number of documents: 1\n",
      "First 200 characters of PDF content:\n",
      "\n",
      "Introduction\n",
      "Whether you have recently graduated, been laid off, or are simply \n",
      "window shopping for new opportunities - if you are reading this book \n",
      "you are in a period of transition. An exciting ti...\n"
     ]
    }
   ],
   "source": [
    "# Extract text from PDF\n",
    "import pypdf\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    \"\"\"Extract text from PDF file\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = pypdf.PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract text from your ResumeBook.pdf\n",
    "pdf_text = extract_pdf_text(\"ResumeBook.pdf\")\n",
    "\n",
    "# Create documents from PDF content\n",
    "docs = [\n",
    "    {\n",
    "        \"id\": \"resume-book\",\n",
    "        \"text\": pdf_text\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Extracted {len(pdf_text)} characters from PDF\")\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "print(f\"First 200 characters of PDF content:\")\n",
    "print(pdf_text[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78081295",
   "metadata": {},
   "source": [
    "## 5) Chunk the text\n",
    "\n",
    "RAG works best when long docs are split into **chunks**. We’ll do a super simple split here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf647a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document: resume-book\n",
      "Text length: 44389 characters\n",
      "Created 20 chunks\n",
      "\n",
      "Total chunks created: 20\n",
      "First chunk preview:\n",
      "ID: resume-book-0\n",
      "Source: resume-book\n",
      "Text: Introduction Whether you have recently graduated, been laid off, or are simply window shopping for new opportunities - if you are reading this book you are in a period of transition. An exciting time,...\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 400, overlap: int = 40) -> List[str]:\n",
    "    \"\"\"Split text into overlapping chunks for better retrieval\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(len(words), start + chunk_size)\n",
    "        chunks.append(' '.join(words[start:end]))\n",
    "        if end == len(words): break\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "# Process the PDF document into chunks\n",
    "chunks: List[Dict] = []\n",
    "for d in docs:\n",
    "    print(f\"Processing document: {d['id']}\")\n",
    "    print(f\"Text length: {len(d['text'])} characters\")\n",
    "    \n",
    "    # Create chunks from the PDF text\n",
    "    text_chunks = chunk_text(d[\"text\"])\n",
    "    print(f\"Created {len(text_chunks)} chunks\")\n",
    "    \n",
    "    for i, ch in enumerate(text_chunks):\n",
    "        chunks.append({\n",
    "            \"id\": f'{d[\"id\"]}-{i}',\n",
    "            \"text\": ch,\n",
    "            \"source\": d[\"id\"]\n",
    "        })\n",
    "\n",
    "print(f\"\\nTotal chunks created: {len(chunks)}\")\n",
    "print(f\"First chunk preview:\")\n",
    "print(f\"ID: {chunks[0]['id']}\")\n",
    "print(f\"Source: {chunks[0]['source']}\")\n",
    "print(f\"Text: {chunks[0]['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d9a78",
   "metadata": {},
   "source": [
    "## 6) Create a Pinecone index and store embeddings\n",
    "\n",
    "We’ll:\n",
    "1. Initialize Pinecone\n",
    "2. Create or connect to an index\n",
    "3. Embed each chunk with **Gemini embeddings**  \n",
    "4. Upsert vectors into Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2df14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760916565.556182   85760 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"rag-demo-gemini\"\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in [i.name for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,  # dimension of text-embedding-004\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Embeddings: Google's newest general embedding model as of 2024+\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "# Build vectors for upsert\n",
    "vectors = []\n",
    "for c in chunks:\n",
    "    vec = embeddings.embed_query(c[\"text\"])  # returns a 768-dim list\n",
    "    vectors.append({\n",
    "        \"id\": c[\"id\"],\n",
    "        \"values\": vec,\n",
    "        \"metadata\": {\"text\": c[\"text\"], \"source\": c[\"source\"]}\n",
    "    })\n",
    "\n",
    "# Upsert to Pinecone\n",
    "index.upsert(vectors=vectors)\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e7ca1",
   "metadata": {},
   "source": [
    "## 7) Build the retriever and the RAG chain (few lines)\n",
    "\n",
    "- **Retriever:** queries Pinecone for the top‑k similar chunks  \n",
    "- **LLM:** Gemini reads the chunks and answers, with simple citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2cc1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified RAG ready. ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760916571.198188   85760 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1760916571.199721   85760 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Init Pinecone\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "index_name = \"rag-demo-gemini\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# LangChain embeddings for querying\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "\n",
    "# LLM for answering\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",  # cheap + fast; swap to gemini-1.5-pro for higher quality\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=(\n",
    "        \"\"\"You are a helpful assistant that answers using only the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Rules:\n",
    "- Be concise and clear.\n",
    "- If the answer is not in the context, say you don't know.\n",
    "- Cite sources at the end as [source:id].\"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def retrieve_docs(question, k=3):\n",
    "    \"\"\"Retrieve relevant documents from Pinecone using direct query\"\"\"\n",
    "    # Generate embedding for the question\n",
    "    query_embedding = embeddings.embed_query(question)\n",
    "    \n",
    "    # Query Pinecone directly\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Format results for the prompt\n",
    "    docs = []\n",
    "    for i, match in enumerate(results.matches, 1):\n",
    "        source = match.metadata.get(\"source\", \"unknown\")\n",
    "        text = match.metadata.get(\"text\", \"\")\n",
    "        docs.append(f\"[{i}] ({source})\\n{text}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(docs)\n",
    "\n",
    "def ask_question(question):\n",
    "    \"\"\"Ask a question and get an answer using RAG\"\"\"\n",
    "    # Retrieve relevant context\n",
    "    context = retrieve_docs(question)\n",
    "    print(\"Context:\")\n",
    "    print(context)\n",
    "    # Format the prompt\n",
    "    formatted_prompt = prompt.format(question=question, context=context)\n",
    "    \n",
    "    # Get answer from LLM\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    return response\n",
    "\n",
    "print(\"Simplified RAG ready. ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b28ae",
   "metadata": {},
   "source": [
    "## 8) Ask questions\n",
    "\n",
    "Now you can ask questions about your resume book! Try questions like:\n",
    "- *Give me tips to prepare a resume*  \n",
    "- *How many pages should my Resume have?*  \n",
    "- *Do I need a cover letter?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa76e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "[1] (resume-book)\n",
      "shows you’re a skilled communicator who is passionate about the company. Adapt your generic cover letter completely to ﬁt the companies’ needs and style. Here are 2 cover letters that got people hired at Crew from Mikael Cho’s article. Notice how the tone and the vibe matches the company. Sample Introductory email Short and sweet cover letter introduction 2. A custom resume Most people send the same generic resume to every employer. This is a huge miss. Every employer has different needs that you need to ﬁll. You need to think like a marketer — send the recruiter to a custom landing page targeted to meeting their needs. More details on customizing your resume can be found in the next section. 3. Bonus: Beef up your online brand Here are some additional things you can do to increase your marketplace value. LinkedIn. Update your LinkedIn with relevant work experience, your summary, and your brand. Add at least 50 people to your network. Twitter. Write a good description of yourself, follow inﬂuencers in the industry, and share relevant content using a tool like Buffer or Hootsuite. An online portfolio. Once you get past the initial resume screen, it’s important to have a place to display your relevant work experiences. Work samples are the best predictor of job success, and employers love to see past projects you’ve impacted. According to our data, recruiters spend 3 minutes and 55 seconds on average viewing an online portfolio. Which means that if you can get them to your online resume — your chances increase exponentially. Don’t forget - along with your resume you can create an awesome portfolio on VisualCV .com. Now that you’re ready to apply to the job - it’s time to write the perfect resume. CHAPTER 6 Writing your resume Now that you have the job in mind, it’s time to write your resume. Creating a master resume Initially, start by writing a “master resume.” This will be a working document that you can then customize for each speciﬁc job application. Having a master resume means you won’t have to start from scratch every time, and it makes the entire process much easier. Gathering the content It’s essential to have all your career information handy before starting to write your resume. Grab a notebook or open up a new document, and write down the following. Don’t worry about being perfect here -\n",
      "\n",
      "[2] (resume-book)\n",
      "• Boosted • Delivered • Lifted • Merged • Modiﬁed • Remodeled • Replaced • Supervised • Trained • Projected • Assessed • Promoted • Oversaw • Improved • Adapted • Trained • Directed • Managed • Solved • Initiated • Controlled • Coordinated • Executed • Produced • Built • Grew Education The education section contains some or all of the following: • Name of School • Degree Earned • Major Course(s) of Study • Academic Distinctions • Extracurricular and Leadership Activities • Training and Certiﬁcation • Additional Professional Development Keys for the education section: The more senior your career, the fewer education details to include. For younger professionals, add in distinguishing information such as achievements or leadership roles. Don’t let your education shadow your experience, and never inﬂate your credentials. Skills Include a listing of your skills on your resume, that includes your level of competency of each skill. Skills are extremely important to match with the job description - don’t use jargon unless it is also in the job description and employers will understand it. The skills section is a good place to include keywords to better match the job description - of course if you do have the skills. References On a print-only resume (or PDF used for a traditional application), there is no need to include references on your resume. Employers will ask for them. The phrase “references available upon request” is also redundant. Use that space for something more impactful. On a web based resume or portfolio, it is perfectly ﬁne to include references. Your ﬁrst resume Once you’ve completed your ﬁrst master resume that includes all the previous sections, you’re almost ready to apply for a job. But not quite. This master resume serves the following purposes: • It can be easily updated for a speciﬁc job application • It can be updated with any future employment • Hosted online at a website like VisualCV .com to improve your web presence and share with colleagues • It can be uploaded to industry speciﬁc resume databases • It can be used for any general career purpose (ie. applying for an award) Your master resume should NOT be used for a job application. It is essential you customize your resume for each application. CHAPTER 7 Customizing your resume For each job application, it is essential you customize it to ﬁt the position and company. Passing\n",
      "\n",
      "[3] (resume-book)\n",
      "of! top! performers! to! call! on! interventional! cardiologists! and! expand! the! organization’s! sales! in! the! Eastern! United! States.! • Delivered!YOY!sales!growth!of!18%!vs.!organic!market!growth!at!1%!annually! ! • Ranked!#1!position!for!Region!of!the!Year!in!2009!and!2010.! • Spearheaded!strategies!to!generate!growth!through!MD!development!initiatives.! • Facilitated!marketing!teams!in!driving!patient!volume!to!structural!physicians. ! Education$and$Training ! Master$in$Business$Administration$(MBA),$Marketing$&$Finance ! City!State!University,!City,!ST! Bachelor$of$Arts,$Accounting$&$Finance ! City!State!University,!City,!ST! Executive$Development$Program City!State!University,!City,!ST! Technology ! Microsoft!Office!Suite:!Word,!Excel,!Access,!Outlook,!PowerPoint! Salesforce.com! See the full database of examples at VisualCV .com/resume-samples CHAPTER 9 Closing thoughts Your resume (like your career) is a continual work in-progress. Throughout your career you will be constantly updating it with new projects and accomplishments. Here’s a life tip for you - don’t think of your resume as a static document. It is reﬂection of your accomplishments in your career that you must continually improve. The way you do anything is the way you do everything, and you should constantly be striving for excellence in your work. The people you meet, the work you do, the reputation you build - all of that is essential to great career. Now go create a resume that reﬂects how great you really are, and never stop working towards improving it. ONE MORE THING Enjoyed this guide? If so, a quick Tweet or Facebook share would be much appreciated!\n",
      "Response:\n",
      "To prepare a resume, follow these tips:\n",
      "\n",
      "1.  **Create a master resume** Start by writing a \"master resume\" as a working document, gathering all your career information. [source:1]\n",
      "2.  **Customize for each application** Do not use your master resume for job applications. It is essential to customize your resume for each specific job application to fit the position and company's needs and style. [source:1, 2]\n",
      "3.  **Education section** Include your school name, degree, major courses, academic distinctions, extracurriculars, leadership activities, training, and certifications. Adjust the level of detail based on your career seniority, adding distinguishing information for younger professionals. Do not inflate credentials. [source:2]\n",
      "4.  **Skills section** List your skills, including your level of competency for each. Match skills with the job description and use keywords. Avoid jargon unless it's also in the job description. [source:2]\n",
      "5.  **References** Do not include references on print-only or PDF resumes, as employers will ask for them. The phrase \"references available upon request\" is redundant. It is acceptable to include references on web-based resumes or portfolios. [source:2]\n",
      "6.  **Beef up your online brand** Update your LinkedIn with relevant work experience, your summary, and your brand, and add to your network. Write a good Twitter description, follow industry influencers, and share relevant content. Create an online portfolio to display work samples. [source:1]\n",
      "7.  **Continual improvement** View your resume as a continual work in progress, constantly updating it with new projects and accomplishments. [source:3]\n"
     ]
    }
   ],
   "source": [
    "question = \"Give me tips to prepare a resume\"\n",
    "response = ask_question(question)\n",
    "print(\"Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dd6f7",
   "metadata": {},
   "source": [
    "## 9) How the pieces fit together\n",
    "\n",
    "1. **Embed** your chunks with Gemini → numbers (vectors) that capture meaning  \n",
    "2. **Store** vectors in **Pinecone** → fast similarity search  \n",
    "3. **Query Pinecone directly** for top‑k chunks using question embedding  \n",
    "4. **Generate** an answer with **Gemini**, using a prompt that **forces grounding** in the retrieved context  \n",
    "5. **Cite** sources so users can verify\n",
    "\n",
    "That’s RAG — retrieve first, then generate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
